# Machine-Learning-Tutorial
# K-Fold vs Stratified K-Fold Cross-Validation â€“ ML Evaluation Tutorial

## Overview

This tutorial presents a clear comparison between K-Fold Cross-Validation and Stratified K-Fold Cross-Validation, both of which are essential techniques for evaluating machine learning models. The tutorial focuses on illustrating how data splitting strategies can impact model performance, especially with imbalanced datasets.

## Objectives

- Explain how traditional K-Fold splitting works
- Show the advantage of stratification in preserving label proportions
- Compare evaluation metrics obtained from both methods
- Visualize data splits to reinforce understanding

## Dataset

- A built-in dataset from sklearn.datasets is used
- Contains class imbalance to highlight the difference in splitting strategies
- No external download or preprocessing is required

## How to Use

1. Launch Jupyter Notebook or JupyterLab.
2. Open the file K_Fold_vs_Stratified_K_Fold.ipynb.
3. Execute the cells sequentially.
4. All libraries used are standard: scikit-learn, matplotlib, numpy, seaborn.
